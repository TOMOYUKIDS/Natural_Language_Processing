{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然言語処理によるトピック分類\n",
    "自然言語処理（以下NLP）により、トピックの分類は可能であるが、どの程度の精度で分類が可能であるか実験をしてみる。\n",
    "使用するデータは、クリエイティブ・コモンズライセンスのもとに提供されている「Livedoor News」を使用し、8トピック、6600文章程度のデータセットとなっている。\n",
    "\n",
    "＜Livedoor News＞\n",
    "- トピックニュース\n",
    "- Sports Watch\n",
    "- ITライフハック\n",
    "- 家電チャンネル\n",
    "- MOVIE ENTER\n",
    "- 独女通信\n",
    "- エスマックス\n",
    "- livedoor HOMME\n",
    "- Peachy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.データセットの読込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://qiita.com/hyo_07/items/ba3d53868b2f55ed9941\n",
    "import os\n",
    "\n",
    "#ファイルの読み込み、及びタイトル・本文データの取得\n",
    "path_list = [\"dokujo-tsushin\", \"it-life-hack\", \"movie-enter\",\"sports-watch\",\"kaden-channel\",\"livedoor-homme\",\"peachy\",\"smax\"]\n",
    "\n",
    "w_list = []\n",
    "labels = []\n",
    "\n",
    "for p_list in path_list:\n",
    "    path = \"./text/\"+p_list\n",
    "    #ディレクトリ内の全ファイル名を取得\n",
    "    f_list = os.listdir(path)\n",
    "\n",
    "    for lists in f_list:\n",
    "        with open(\"./text/\"+ p_list+ \"/\"+lists, encoding=\"utf-8_sig\") as f:\n",
    "            next(f)\n",
    "            next(f)\n",
    "            #全角スペースや改行の削除\n",
    "            w = f.read().replace('\\u3000','').replace('\\n','')\n",
    "\n",
    "            w_list.append(w)\n",
    "            labels.append(path_list.index(p_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alldata.shape: (6605, 2)\n",
      "alldata['label'].unique(): [0 1 2 3 4 5 6 7]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>友人代表のスピーチ、独女はどうこなしている？もうすぐジューン・ブライドと呼ばれる６月。独女の...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ネットで断ち切れない元カレとの縁携帯電話が普及する以前、恋人への連絡ツールは一般電話が普通だ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>相次ぐ芸能人の“すっぴん”披露その時、独女の心境は？「男性はやっぱり、女性の“すっぴん”が大...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ムダな抵抗！？ 加齢の現実ヒップの加齢による変化は「たわむ→下がる→内に流れる」、バストは「...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>税金を払うのは私たちなんですけど！6月から支給される子ども手当だが、当初は子ども一人当たり月...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6600</th>\n",
       "      <td>キレイに撮れる！docomoのスマホ「GALAXY S III SC-06D」のカメラでE2...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6601</th>\n",
       "      <td>Sony Mobile、4.6インチディスプレイを搭載したスマートフォン「Xperia T」...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>タブレットもXperiaブランドへ！ソニー、9.4インチAndroidタブレット「Xperi...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603</th>\n",
       "      <td>かわいいから大人買いしたい！邪魔なケーブルをすっきりできる「ドロイド君 ケーブルホルダー」【...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>【究極にカスタマイズされたAndroidスマートフォンが遂に登場！使いやすさに特化した「らく...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6605 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     友人代表のスピーチ、独女はどうこなしている？もうすぐジューン・ブライドと呼ばれる６月。独女の...      0\n",
       "1     ネットで断ち切れない元カレとの縁携帯電話が普及する以前、恋人への連絡ツールは一般電話が普通だ...      0\n",
       "2     相次ぐ芸能人の“すっぴん”披露その時、独女の心境は？「男性はやっぱり、女性の“すっぴん”が大...      0\n",
       "3     ムダな抵抗！？ 加齢の現実ヒップの加齢による変化は「たわむ→下がる→内に流れる」、バストは「...      0\n",
       "4     税金を払うのは私たちなんですけど！6月から支給される子ども手当だが、当初は子ども一人当たり月...      0\n",
       "...                                                 ...    ...\n",
       "6600  キレイに撮れる！docomoのスマホ「GALAXY S III SC-06D」のカメラでE2...      7\n",
       "6601  Sony Mobile、4.6インチディスプレイを搭載したスマートフォン「Xperia T」...      7\n",
       "6602  タブレットもXperiaブランドへ！ソニー、9.4インチAndroidタブレット「Xperi...      7\n",
       "6603  かわいいから大人買いしたい！邪魔なケーブルをすっきりできる「ドロイド君 ケーブルホルダー」【...      7\n",
       "6604  【究極にカスタマイズされたAndroidスマートフォンが遂に登場！使いやすさに特化した「らく...      7\n",
       "\n",
       "[6605 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata=pd.DataFrame({\"text\":w_list,\"label\":labels})\n",
    "print(\"alldata.shape:\",alldata.shape)\n",
    "print(\"alldata['label'].unique():\",alldata['label'].unique())\n",
    "alldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata_original=alldata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'友人代表のスピーチ、独女はどうこなしている？もうすぐジューン・ブライドと呼ばれる６月。独女の中には自分の式はまだなのに呼ばれてばかり……という「お祝い貧乏」状態の人も多いのではないだろうか？さらに出席回数を重ねていくと、こんなお願いごとをされることも少なくない。「お願いがあるんだけど……友人代表のスピーチ、やってくれないかな？」さてそんなとき、独女はどう対応したらいいか？最近だとインターネット等で検索すれば友人代表スピーチ用の例文サイトがたくさん出てくるので、それらを参考にすれば、無難なものは誰でも作成できる。しかし由利さん（33歳）はネットを参考にして作成したものの「これで本当にいいのか不安でした。一人暮らしなので聞かせて感想をいってくれる人もいないし、かといって他の友人にわざわざ聞かせるのもどうかと思うし……」ということで活用したのが、なんとインターネットの悩み相談サイトに。そこに作成したスピーチ文を掲載し「これで大丈夫か添削してください」とメッセージを送ったというのである。「一晩で3人位の人が添削してくれましたよ。ちなみに自分以外にもそういう人はたくさんいて、その相談サイトには同じように添削をお願いする投稿がいっぱいありました」（由利さん）。ためしに教えてもらったそのサイトをみてみると、確かに「結婚式のスピーチの添削お願いします」という投稿が1000件を超えるくらいあった。めでたい結婚式の影でこんなネットコミュニティがあったとは知らなかった。しかし「事前にお願いされるスピーチなら準備ができるしまだいいですよ。一番嫌なのは何といってもサプライズスピーチ！」と語るのは昨年だけで10万以上お祝いにかかったというお祝い貧乏独女の薫さん（35歳）「私は基本的に人前で話すのが苦手なんですよ。だからいきなり指名されるとしどろもどろになって何もいえなくなる。そうすると自己嫌悪に陥って終わった後でもまったく楽しめなくなりますね」サプライズスピーチのメリットとしては、準備していない状態なので、フランクな本音をしゃべってもらえるという楽しさがあるようだ。しかしそれも上手に対応できる人ならいいが、苦手な人の場合だと「フランク」ではなく「しどろもどろ」になる危険性大。ちなみにプロの司会者の場合、本当のサプライズではなく式の最中に「のちほどサプライズスピーチとしてご指名させていただきます」という一言があることも多いようだが、薫さん曰く「そんな何分前に言われても無理！」らしい。要は「サプライズを楽しめる」というタイプの人選が大切ということか。一方「ありきたりじゃつまらないし、ネットで例文を検索している際に『こんな方法もあるのか！』って思って取り入れました」という幸恵さん（30歳）が行ったスピーチは「手紙形式のスピーチ」というもの。「○○ちゃんへみたいな感じで新婦の友人にお手紙を書いて読み上げるやり方です。これなら多少フランクな書き方でも大丈夫だし、何より暗記しないで堂々と読み上げることができますよね。読んだものはそのまま友人にあげれば一応記念にもなります」（幸恵さん）なるほど、確かにこれなら読みあげればいいだけなので、人前で話すのが苦手な人でも失敗しないかもしれない。主役はあくまで新郎新婦ながらも、いざとなると緊張し、内容もあれこれ考えて、こっそりリハーサル……そんな人知れず頑張るスピーチ担当独女たちにも幸あれ（高山惠）'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata_original.loc[0,'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各トピックの割合を確認\n",
    "6600文章、8トピックのデータセットであるが、ほとんどのデータセットは13%～14%と同程度の割合で保存されていることがわかる。トピック5のみ、8%と他のトピックと比較してデータは少なめである。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3   0.14\n",
       "0   0.13\n",
       "1   0.13\n",
       "2   0.13\n",
       "7   0.13\n",
       "4   0.13\n",
       "6   0.13\n",
       "5   0.08\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata_original['label'].value_counts(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.自然言語の前処理\n",
    "自然言語の前処理として、正規表現による文字の除去、表記のゆれの統一、全角、半角の統一、ストップワードの設定、不要な言葉の削除を行う。\n",
    "モデルの精度が十分で無い場合、以下の各前処理を工夫して精度向上を行う。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.HTML表記の除去\n",
    "今回は「Livedoor News」のデータセットを使用しているが、自然言語処理を行う場合、APIの活用、スクレイピングなどをしてデータを取得する場合があり、その場合は、分析に本質的に必要でないメタタグ（</A>など）を除去する必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HTMLを除去\n",
    "\n",
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                           text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
    "            ' '.join(emoticons).replace('-', ''))\n",
    "    return text\n",
    "\n",
    "alldata['text']=alldata['text'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.表記ゆれの統一\n",
    "本質的に同一の人、物、をさしているが表現が違っていることがある。（例：「山田君」、「山田さん」）これを「表記ゆれ」という。モデルを作るうえで、同じものをさしていることをモデルに学習させたいため、前処理として表現が違うが、同じものを表している場合、表現を統一する処理を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#表記ゆれの統一\n",
    "import re\n",
    "def replace_yamada(text):\n",
    "    replaced_text = re.sub(r'山田君', '山田さん', text)\n",
    "    return replaced_text\n",
    "\n",
    "#pandasaへ適用する場合\n",
    "#targetという新しいカラムを作ることで元データを汚さないようにしています\n",
    "alldata[\"text\"] = alldata[\"text\"].apply(replace_yamada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.全角、半角の統一\n",
    "全角と半角は本質的には同じであるが、モデルは別のものと判断してしまうため、すべて全角、またはすべて半角などにして、表現を統一してやる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#全角を半角に変換\n",
    "import mojimoji\n",
    "\n",
    "alldata['text']=alldata['text'].apply(mojimoji.zen_to_han)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.数字の削除\n",
    "トピック分類を行う上で数字が大きな意味を持たないと考えられる場合、最初に数値を削除する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数字をスペースに変換\n",
    "def normalize_number(text):\n",
    "    replaced_text = re.sub(r'\\d+', '', text)\n",
    "    return replaced_text\n",
    "    \n",
    "alldata[\"text\"] = alldata[\"text\"].apply(normalize_number) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.形態素解析\n",
    "英語は、単語がスペースによって区切られているが、日本語はそのようなことはない。 \n",
    "ここではMeCabを使用して、各文から名詞のみを取り出し、各文章がどのトピックに所属するか分析する。 \n",
    "精度が十分で無い場合は、動詞、形容詞なども含めてモデルの作成を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "def wakati_by_mecab(text):\n",
    "    tagger = MeCab.Tagger('')\n",
    "    tagger.parse('') \n",
    "    node = tagger.parseToNode(text)\n",
    "    word_list = []\n",
    "    while node:\n",
    "        pos = node.feature.split(\",\")[0]\n",
    "        if pos in [\"名詞\"]:   # 対象とする品詞 [\"名詞\", \"動詞\", \"形容詞\"]\n",
    "            word = node.surface\n",
    "            word_list.append(word)\n",
    "        node = node.next\n",
    "    return \" \".join(word_list)\n",
    "\n",
    "alldata[\"text\"] = alldata[\"text\"].apply(wakati_by_mecab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.ストップワードの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopword\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "def download_stopwords(path):\n",
    "    url = 'http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt'\n",
    "    if os.path.exists(path):\n",
    "        print('File already exists.')\n",
    "    else:\n",
    "        print('Downloading...')\n",
    "        # Download the file from `url` and save it locally under `file_name`:\n",
    "        urllib.request.urlretrieve(url, path)\n",
    "\n",
    "def create_stopwords(file_path):\n",
    "    stop_words = []\n",
    "    for w in open(path, \"r\",encoding=\"utf-8_sig\"):\n",
    "        w = w.replace('\\n','')\n",
    "        if len(w) > 0:\n",
    "            stop_words.append(w)\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists.\n"
     ]
    }
   ],
   "source": [
    "path = \"stop_words.txt\"\n",
    "download_stopwords(path)\n",
    "stop_words = create_stopwords(path)\n",
    "\n",
    "alldata[\"text\"] = alldata[\"text\"].apply(wakati_by_mecab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.単語文書行列の作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words=stop_words,token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "feature_vectors_cnt = count_vectorizer.fit_transform(alldata[\"text\"])\n",
    "vocabulary_cnt = count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_</th>\n",
       "      <th>__</th>\n",
       "      <th>a</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aac</th>\n",
       "      <th>aae</th>\n",
       "      <th>aaf</th>\n",
       "      <th>aandroid</th>\n",
       "      <th>...</th>\n",
       "      <th>ﾝﾀｯｸｽﾘｺｰｲﾒｰｼﾞﾝｸﾞﾎｰﾑﾍﾟｰｼﾞ</th>\n",
       "      <th>ﾝﾃﾞｽ</th>\n",
       "      <th>ﾝﾊ</th>\n",
       "      <th>ﾞｱｲﾝﾀｰﾅｼｮﾅﾙﾃﾞｺｽﾏｰﾄﾌｫﾝｶﾊﾞｰ</th>\n",
       "      <th>ﾞｼｬｰﾌﾟﾎｰﾑﾍﾟｰｼﾞｿﾆｰﾎｰﾑﾍﾟｰｼﾞ</th>\n",
       "      <th>ﾞﾃﾞｵｶﾒﾗﾌﾟﾛｼﾞｪｸﾀｰﾋﾞﾃﾞｵｶﾒﾗ</th>\n",
       "      <th>ﾟｭ</th>\n",
       "      <th>ﾟｯ</th>\n",
       "      <th>ﾟｰﾌﾟﾚｾﾞﾝﾄｷｬﾝﾍﾟｰﾝｲﾝﾓｰﾀﾙｽﾞ</th>\n",
       "      <th>ﾟｶﾄﾘｭﾌｧｽｾﾚｸｼｮﾝｵﾘｵｰﾙﾊﾞﾗｹﾞ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6600</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6601</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6605 rows × 61401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      _  __  a  aa  aaa  aaaa  aac  aae  aaf  aandroid  ...  \\\n",
       "0     0   0  0   0    0     0    0    0    0         0  ...   \n",
       "1     0   0  0   0    0     0    0    0    0         0  ...   \n",
       "2     0   0  0   0    0     0    0    0    0         0  ...   \n",
       "3     0   0  1   0    0     0    0    0    0         0  ...   \n",
       "4     0   0  0   0    0     0    0    0    0         0  ...   \n",
       "...  ..  .. ..  ..  ...   ...  ...  ...  ...       ...  ...   \n",
       "6600  0   0  0   0    0     0    0    0    0         0  ...   \n",
       "6601  0   0  2   0    0     0    0    0    0         0  ...   \n",
       "6602  0   0  1   0    0     0    0    0    0         0  ...   \n",
       "6603  0   0  0   0    0     0    0    0    0         0  ...   \n",
       "6604  0   0  0   0    0     0    0    0    0         0  ...   \n",
       "\n",
       "      ﾝﾀｯｸｽﾘｺｰｲﾒｰｼﾞﾝｸﾞﾎｰﾑﾍﾟｰｼﾞ  ﾝﾃﾞｽ  ﾝﾊ  ﾞｱｲﾝﾀｰﾅｼｮﾅﾙﾃﾞｺｽﾏｰﾄﾌｫﾝｶﾊﾞｰ  \\\n",
       "0                            0     0   0                          0   \n",
       "1                            0     0   0                          0   \n",
       "2                            0     0   0                          0   \n",
       "3                            0     0   0                          0   \n",
       "4                            0     0   0                          0   \n",
       "...                        ...   ...  ..                        ...   \n",
       "6600                         0     0   0                          0   \n",
       "6601                         0     0   0                          0   \n",
       "6602                         0     0   0                          0   \n",
       "6603                         0     0   0                          0   \n",
       "6604                         0     0   0                          0   \n",
       "\n",
       "      ﾞｼｬｰﾌﾟﾎｰﾑﾍﾟｰｼﾞｿﾆｰﾎｰﾑﾍﾟｰｼﾞ  ﾞﾃﾞｵｶﾒﾗﾌﾟﾛｼﾞｪｸﾀｰﾋﾞﾃﾞｵｶﾒﾗ  ﾟｭ  ﾟｯ  \\\n",
       "0                             0                         0   0   0   \n",
       "1                             0                         0   0   0   \n",
       "2                             0                         0   0   0   \n",
       "3                             0                         0   0   0   \n",
       "4                             0                         0   0   0   \n",
       "...                         ...                       ...  ..  ..   \n",
       "6600                          0                         0   0   0   \n",
       "6601                          0                         0   0   0   \n",
       "6602                          0                         0   0   0   \n",
       "6603                          0                         0   0   0   \n",
       "6604                          0                         0   0   0   \n",
       "\n",
       "      ﾟｰﾌﾟﾚｾﾞﾝﾄｷｬﾝﾍﾟｰﾝｲﾝﾓｰﾀﾙｽﾞ  ﾟｶﾄﾘｭﾌｧｽｾﾚｸｼｮﾝｵﾘｵｰﾙﾊﾞﾗｹﾞ  \n",
       "0                            0                         0  \n",
       "1                            0                         0  \n",
       "2                            0                         0  \n",
       "3                            0                         0  \n",
       "4                            0                         0  \n",
       "...                        ...                       ...  \n",
       "6600                         0                         0  \n",
       "6601                         0                         0  \n",
       "6602                         0                         0  \n",
       "6603                         0                         0  \n",
       "6604                         0                         0  \n",
       "\n",
       "[6605 rows x 61401 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(feature_vectors_cnt.toarray(), columns=vocabulary_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cnt = feature_vectors_cnt.toarray()\n",
    "y_cnt = alldata['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cnt, y_cnt, test_size=0.3, random_state=0, stratify=y_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(count_vectorizer): 0.946 ± 0.009\n",
      "Wall time: 54.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "LGBMC=LGBMClassifier(random_state=0)\n",
    "LGBMC.fit(X_train,y_train)\n",
    "y_pred = LGBMC.predict(X_test)\n",
    "\n",
    "\n",
    "scores = cross_val_score(estimator=LGBMC, X=X_train, y=y_train, cv=10, n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy(count_vectorizer): %.3f ± %.3f\" % (np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "feature_vectors_Tfidf = tfidf.fit_transform(alldata[\"text\"])\n",
    "vocabulary_Tfidf = tfidf.get_feature_names() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_</th>\n",
       "      <th>__</th>\n",
       "      <th>a</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aac</th>\n",
       "      <th>aae</th>\n",
       "      <th>aaf</th>\n",
       "      <th>aandroid</th>\n",
       "      <th>...</th>\n",
       "      <th>ﾝﾀｯｸｽﾘｺｰｲﾒｰｼﾞﾝｸﾞﾎｰﾑﾍﾟｰｼﾞ</th>\n",
       "      <th>ﾝﾃﾞｽ</th>\n",
       "      <th>ﾝﾊ</th>\n",
       "      <th>ﾞｱｲﾝﾀｰﾅｼｮﾅﾙﾃﾞｺｽﾏｰﾄﾌｫﾝｶﾊﾞｰ</th>\n",
       "      <th>ﾞｼｬｰﾌﾟﾎｰﾑﾍﾟｰｼﾞｿﾆｰﾎｰﾑﾍﾟｰｼﾞ</th>\n",
       "      <th>ﾞﾃﾞｵｶﾒﾗﾌﾟﾛｼﾞｪｸﾀｰﾋﾞﾃﾞｵｶﾒﾗ</th>\n",
       "      <th>ﾟｭ</th>\n",
       "      <th>ﾟｯ</th>\n",
       "      <th>ﾟｰﾌﾟﾚｾﾞﾝﾄｷｬﾝﾍﾟｰﾝｲﾝﾓｰﾀﾙｽﾞ</th>\n",
       "      <th>ﾟｶﾄﾘｭﾌｧｽｾﾚｸｼｮﾝｵﾘｵｰﾙﾊﾞﾗｹﾞ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6601</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6605 rows × 61690 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        _   __    a   aa  aaa  aaaa  aac  aae  aaf  aandroid  ...  \\\n",
       "0    0.00 0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00      0.00  ...   \n",
       "1    0.00 0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00      0.00  ...   \n",
       "2    0.00 0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00      0.00  ...   \n",
       "3    0.00 0.00 0.03 0.00 0.00  0.00 0.00 0.00 0.00      0.00  ...   \n",
       "4    0.00 0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00      0.00  ...   \n",
       "...   ...  ...  ...  ...  ...   ...  ...  ...  ...       ...  ...   \n",
       "6600 0.00 0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00      0.00  ...   \n",
       "6601 0.00 0.00 0.03 0.00 0.00  0.00 0.00 0.00 0.00      0.00  ...   \n",
       "6602 0.00 0.00 0.02 0.00 0.00  0.00 0.00 0.00 0.00      0.00  ...   \n",
       "6603 0.00 0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00      0.00  ...   \n",
       "6604 0.00 0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00      0.00  ...   \n",
       "\n",
       "      ﾝﾀｯｸｽﾘｺｰｲﾒｰｼﾞﾝｸﾞﾎｰﾑﾍﾟｰｼﾞ  ﾝﾃﾞｽ   ﾝﾊ  ﾞｱｲﾝﾀｰﾅｼｮﾅﾙﾃﾞｺｽﾏｰﾄﾌｫﾝｶﾊﾞｰ  \\\n",
       "0                         0.00  0.00 0.00                       0.00   \n",
       "1                         0.00  0.00 0.00                       0.00   \n",
       "2                         0.00  0.00 0.00                       0.00   \n",
       "3                         0.00  0.00 0.00                       0.00   \n",
       "4                         0.00  0.00 0.00                       0.00   \n",
       "...                        ...   ...  ...                        ...   \n",
       "6600                      0.00  0.00 0.00                       0.00   \n",
       "6601                      0.00  0.00 0.00                       0.00   \n",
       "6602                      0.00  0.00 0.00                       0.00   \n",
       "6603                      0.00  0.00 0.00                       0.00   \n",
       "6604                      0.00  0.00 0.00                       0.00   \n",
       "\n",
       "      ﾞｼｬｰﾌﾟﾎｰﾑﾍﾟｰｼﾞｿﾆｰﾎｰﾑﾍﾟｰｼﾞ  ﾞﾃﾞｵｶﾒﾗﾌﾟﾛｼﾞｪｸﾀｰﾋﾞﾃﾞｵｶﾒﾗ   ﾟｭ   ﾟｯ  \\\n",
       "0                          0.00                      0.00 0.00 0.00   \n",
       "1                          0.00                      0.00 0.00 0.00   \n",
       "2                          0.00                      0.00 0.00 0.00   \n",
       "3                          0.00                      0.00 0.00 0.00   \n",
       "4                          0.00                      0.00 0.00 0.00   \n",
       "...                         ...                       ...  ...  ...   \n",
       "6600                       0.00                      0.00 0.00 0.00   \n",
       "6601                       0.00                      0.00 0.00 0.00   \n",
       "6602                       0.00                      0.00 0.00 0.00   \n",
       "6603                       0.00                      0.00 0.00 0.00   \n",
       "6604                       0.00                      0.00 0.00 0.00   \n",
       "\n",
       "      ﾟｰﾌﾟﾚｾﾞﾝﾄｷｬﾝﾍﾟｰﾝｲﾝﾓｰﾀﾙｽﾞ  ﾟｶﾄﾘｭﾌｧｽｾﾚｸｼｮﾝｵﾘｵｰﾙﾊﾞﾗｹﾞ  \n",
       "0                         0.00                      0.00  \n",
       "1                         0.00                      0.00  \n",
       "2                         0.00                      0.00  \n",
       "3                         0.00                      0.00  \n",
       "4                         0.00                      0.00  \n",
       "...                        ...                       ...  \n",
       "6600                      0.00                      0.00  \n",
       "6601                      0.00                      0.00  \n",
       "6602                      0.00                      0.00  \n",
       "6603                      0.00                      0.00  \n",
       "6604                      0.00                      0.00  \n",
       "\n",
       "[6605 rows x 61690 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(feature_vectors_Tfidf.toarray(), columns=vocabulary_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Tfidf = feature_vectors_Tfidf.toarray()\n",
    "# X_Tfidf = feature_vectors_Tfidf.values\n",
    "y_Tfidf = alldata['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 987 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_Tfidf, X_test_Tfidf, y_train_Tfidf, y_test_Tfidf = train_test_split(X_Tfidf, y_Tfidf, test_size=0.3, random_state=0, stratify=y_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(count_Tfidf): 0.949 ± 0.010\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "LGBMC=LGBMClassifier(random_state=0)\n",
    "LGBMC.fit(X_train_Tfidf,y_train_Tfidf)\n",
    "y_pred = LGBMC.predict(X_test_Tfidf)\n",
    "\n",
    "scores = cross_val_score(estimator=LGBMC, X=X_train_Tfidf, y=y_train_Tfidf, cv=10, n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy(count_Tfidf): %.3f ± %.3f\" % (np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_Tfidf = LGBMC.predict(X_test_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [token.split(\" \") for token in alldata['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CBOWモデルの学習\n",
    "from gensim.models import word2vec\n",
    "cbow_model = word2vec.Word2Vec(sentences,\n",
    "                                       sg=0,\n",
    "                                       size=250,\n",
    "                                       min_count=5,\n",
    "                                       window=15,\n",
    "                                       seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成したモデルの保存\n",
    "cbow_model.save(\"Livedoor_cbow_w2v.model\")\n",
    "# saveしたモデルを読み込む時は\n",
    "# model = word2vec.Word2Vec.load(\"./w2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>一人暮らし</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>自炊</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>財布</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>小銭</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>晩酌</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>夕食</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>発泡</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ｸﾘｰﾆﾝｸﾞ</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ﾗﾝﾁ</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>弁当</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword  score\n",
       "0    一人暮らし   0.88\n",
       "1       自炊   0.87\n",
       "2       財布   0.87\n",
       "3       小銭   0.86\n",
       "4       晩酌   0.86\n",
       "5       夕食   0.86\n",
       "6       発泡   0.85\n",
       "7  ｸﾘｰﾆﾝｸﾞ   0.85\n",
       "8      ﾗﾝﾁ   0.84\n",
       "9       弁当   0.84"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ここで記載しているscoreは、単語同士のコサイン類似度です。\n",
    "pd.DataFrame(cbow_model.wv.most_similar(positive=['外食']), columns=[\"keyword\", \"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip-gramモデルの学習\n",
    "skipgram_model = word2vec.Word2Vec(sentences,\n",
    "                                               sg=1, \n",
    "                                               size=250,\n",
    "                                               min_count=10,\n",
    "                                               window=15, seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成したモデルの保存\n",
    "skipgram_model.save(\"skipgram_w2v.model\")\n",
    "# saveしたモデルを読み込む時は\n",
    "# model = word2vec.Word2Vec.load(\"./skipgram_w2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>自炊</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ご馳走</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ﾗﾝﾁﾀｲﾑ</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>働き</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>夕飯</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>夕食</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>分担</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>やりくり</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>おかず</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>台所</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword  score\n",
       "0      自炊   0.81\n",
       "1     ご馳走   0.77\n",
       "2  ﾗﾝﾁﾀｲﾑ   0.75\n",
       "3      働き   0.73\n",
       "4      夕飯   0.72\n",
       "5      夕食   0.71\n",
       "6      分担   0.71\n",
       "7    やりくり   0.71\n",
       "8     おかず   0.71\n",
       "9      台所   0.70"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 外食と似たキーワードを見つけていきます。ここで記載しているscoreは、単語同士のコサイン類似度です。\n",
    "pd.DataFrame(skipgram_model.wv.most_similar(positive=['外食']), columns=[\"keyword\", \"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.949 ± 0.010\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=LGBMC, X=X_train_Tfidf, y=y_train_Tfidf, cv=10, n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.3f ± %.3f\" % (np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.モデルの精度の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9566094853683148\n",
      "\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       261\n",
      "           1       0.98      0.97      0.97       261\n",
      "           2       0.96      0.98      0.97       261\n",
      "           3       0.97      0.99      0.98       271\n",
      "           4       0.98      0.98      0.98       260\n",
      "           5       0.95      0.80      0.87       154\n",
      "           6       0.85      0.94      0.89       253\n",
      "           7       1.00      0.99      0.99       261\n",
      "\n",
      "    accuracy                           0.96      1982\n",
      "   macro avg       0.96      0.95      0.95      1982\n",
      "weighted avg       0.96      0.96      0.96      1982\n",
      "\n",
      "Confusion matrix:\n",
      "[[245   1   1   1   0   1  12   0]\n",
      " [  1 253   0   2   2   0   3   0]\n",
      " [  0   1 256   0   0   0   4   0]\n",
      " [  1   0   0 268   1   0   1   0]\n",
      " [  0   3   0   0 255   0   2   0]\n",
      " [  1   1   3   4   3 123  19   0]\n",
      " [  2   0   8   0   0   5 238   0]\n",
      " [  0   0   0   0   0   1   2 258]]\n"
     ]
    }
   ],
   "source": [
    "# Accuracy, Precision/Recall/F-score/Support, Confusion Matrix を表示\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import fbeta_score, make_scorer, accuracy_score\n",
    "\n",
    "def show_evaluation_metrics(y_test, y_pred_Tfidf):\n",
    "    print(\"Accuracy:\")\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print()\n",
    "    \n",
    "    print(\"Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "show_evaluation_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結論\n",
    "今回は各文章から「名詞」だけを取り出して分類を行ったが、Accuracyが95.7%と非常に高い精度で分類が出来ることができた。\n",
    "またコサイン類似度を測った結果、関係する単語を確認することが出来ており、ある程度想定通り動いていることが確認できた。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "- 機械学習・深層学習による自然言語処理入門(マイナビブックス)\n",
    "- Python3×日本語：自然言語処理の前処理まとめ　https://qiita.com/chamao/items/7edaba62b120a660657e\n",
    "- ニュース記事の分類を機械学習で予測する https://qiita.com/hyo_07/items/ba3d53868b2f55ed9941"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
